{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"TSQes2nq06lK"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1701998853566,"user":{"displayName":"최유민","userId":"14691279395225646105"},"user_tz":-540},"id":"PmrNOnmYT2D3"},"outputs":[],"source":["import os"]},{"cell_type":"markdown","metadata":{"id":"Eyhuu65QUTIy"},"source":["### Prepare Dataset"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1701998853566,"user":{"displayName":"최유민","userId":"14691279395225646105"},"user_tz":-540},"id":"V8fblLAZ8WzJ"},"outputs":[],"source":["# download coco dataset in colab runtime memory\n","os.makedirs('data/coco')\n","os.makedirs('data/coco/annotations')"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1701998858629,"user":{"displayName":"최유민","userId":"14691279395225646105"},"user_tz":-540},"id":"kj4671ZYUGAh","outputId":"c041ff8d-e442-4bc8-8b76-0b63d9855bee"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/data/coco\n"]}],"source":["cd data/coco"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":435008,"status":"ok","timestamp":1701999293635,"user":{"displayName":"최유민","userId":"14691279395225646105"},"user_tz":-540},"id":"oHQloGnH2GKq","outputId":"e6b5d677-e155-4010-f744-fdf11202657a"},"outputs":[{"name":"stdout","output_type":"stream","text":["--2023-12-08 01:27:37--  http://images.cocodataset.org/zips/train2017.zip\n","Resolving images.cocodataset.org (images.cocodataset.org)... 54.231.134.25, 52.217.104.244, 52.217.229.9, ...\n","Connecting to images.cocodataset.org (images.cocodataset.org)|54.231.134.25|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 19336861798 (18G) [application/zip]\n","Saving to: ‘train2017.zip’\n","\n","train2017.zip       100%[===================\u003e]  18.01G  48.5MB/s    in 7m 1s   \n","\n","2023-12-08 01:34:38 (43.9 MB/s) - ‘train2017.zip’ saved [19336861798/19336861798]\n","\n","--2023-12-08 01:34:38--  http://images.cocodataset.org/zips/val2017.zip\n","Resolving images.cocodataset.org (images.cocodataset.org)... 52.216.240.212, 16.182.39.129, 52.217.229.65, ...\n","Connecting to images.cocodataset.org (images.cocodataset.org)|52.216.240.212|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 815585330 (778M) [application/zip]\n","Saving to: ‘val2017.zip’\n","\n","val2017.zip         100%[===================\u003e] 777.80M  58.9MB/s    in 14s     \n","\n","2023-12-08 01:34:52 (56.2 MB/s) - ‘val2017.zip’ saved [815585330/815585330]\n","\n"]}],"source":["!wget http://images.cocodataset.org/zips/train2017.zip\n","!wget http://images.cocodataset.org/zips/val2017.zip\n","#!wget http://images.cocodataset.org/zips/test2017.zip"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":198278,"status":"ok","timestamp":1701999491909,"user":{"displayName":"최유민","userId":"14691279395225646105"},"user_tz":-540},"id":"gbwjF28Z98v1"},"outputs":[],"source":["!unzip -qq \"/content/data/coco/train2017.zip\"\n","!unzip -qq \"/content/data/coco/val2017.zip\"\n","#!unzip -qq \"/content/coco/test2017.zip\"\n"]},{"cell_type":"markdown","metadata":{"id":"Q-8VyjRJUXgj"},"source":["### CLIP"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2458,"status":"ok","timestamp":1701999585395,"user":{"displayName":"최유민","userId":"14691279395225646105"},"user_tz":-540},"id":"Q8Oi_vVv1BhD","outputId":"06571085-9e4f-4a3e-acf1-fd810bf686c9"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/DeepLearning/DL_final_project/DL-final_project/CLIP_prefix_caption\n"]}],"source":["cd /content/drive/MyDrive/Colab Notebooks/DeepLearning/DL_final_project/DL-final_project/CLIP_prefix_caption"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8467,"status":"ok","timestamp":1701999593859,"user":{"displayName":"최유민","userId":"14691279395225646105"},"user_tz":-540},"id":"UxrPuX2hR4z0","outputId":"d3231dba-3625-4498-a7c9-82292b712e2d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting openai-clip\n","  Downloading openai-clip-1.0.1.tar.gz (1.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting ftfy (from openai-clip)\n","  Downloading ftfy-6.1.3-py3-none-any.whl (53 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.4/53.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from openai-clip) (2023.6.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-clip) (4.66.1)\n","Requirement already satisfied: wcwidth\u003c0.3.0,\u003e=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy-\u003eopenai-clip) (0.2.12)\n","Building wheels for collected packages: openai-clip\n","  Building wheel for openai-clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for openai-clip: filename=openai_clip-1.0.1-py3-none-any.whl size=1368605 sha256=4075a9adb8fca5b16d865c840d6b80aa939c0107f27db927294d89dd29043cd5\n","  Stored in directory: /root/.cache/pip/wheels/08/77/8e/8d2f862df6bf7fb4e2007062d2cbaeae49862ec7b56d041229\n","Successfully built openai-clip\n","Installing collected packages: ftfy, openai-clip\n","Successfully installed ftfy-6.1.3 openai-clip-1.0.1\n"]}],"source":["!pip install openai-clip"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":5368,"status":"ok","timestamp":1701999599212,"user":{"displayName":"최유민","userId":"14691279395225646105"},"user_tz":-540},"id":"Hry2U_aXa6-d"},"outputs":[],"source":["import clip"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1701999599214,"user":{"displayName":"최유민","userId":"14691279395225646105"},"user_tz":-540},"id":"Vrx8Ti26RYKb","outputId":"6a1e4e36-09e1-4855-8365-76dadcc3c786"},"outputs":[{"data":{"text/plain":["['RN50',\n"," 'RN101',\n"," 'RN50x4',\n"," 'RN50x16',\n"," 'RN50x64',\n"," 'ViT-B/32',\n"," 'ViT-B/16',\n"," 'ViT-L/14',\n"," 'ViT-L/14@336px']"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["clip.available_models()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-RIWBl8aLn-F"},"outputs":[],"source":["# Pre Trained 된 CLIP 모델을 이용, 이미지를 CLIP Encoder 통과\n","# clip model ViT-B/32 is used in ClipCap paper\n","\n","!python parse_coco.py --clip_model_type ViT-B/32 --data_path '/content/data/coco' --out_path '/content/drive/MyDrive/Colab Notebooks/DeepLearning/DL_final_project/DL-final_project/CLIP_prefix_caption/data/coco' --start_index 560000"]},{"cell_type":"markdown","metadata":{"id":"CVinYb46-93C"},"source":["### Train Prefix Network"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"uuEK8pb-LoAM"},"outputs":[{"name":"stdout","output_type":"stream","text":["vocab.json: 100% 1.04M/1.04M [00:00\u003c00:00, 3.87MB/s]\n","merges.txt: 100% 456k/456k [00:00\u003c00:00, 3.25MB/s]\n","tokenizer.json: 100% 1.36M/1.36M [00:00\u003c00:00, 4.16MB/s]\n","config.json: 100% 665/665 [00:00\u003c00:00, 3.44MB/s]\n","Data size is 566747\n","model.safetensors: 100% 548M/548M [00:05\u003c00:00, 103MB/s]\n","generation_config.json: 100% 124/124 [00:00\u003c00:00, 717kB/s]\n","Train only prefix\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u003e\u003e\u003e Training epoch 0\n","coco_prefix:   2% 314/14337 [02:48\u003c2:07:34,  1.83it/s, loss=4.4]"]}],"source":["!python train.py --data ./data/coco/oscar_split_ViT-B_32_train.pkl --out_dir ./coco_train/ --only_prefix --mapping_type transformer --num_layers 8"]},{"cell_type":"markdown","metadata":{"id":"4ppoSg2sAtK4"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mZlbRlIpLoEF"},"outputs":[],"source":["!python train.py --only_prefix --data ./data/coco/oscar_split_ViT-B_32_train.pkl --out_dir ./coco_train/ --mapping_type transformer  --num_layres 8 --prefix_length 40 --prefix_length_clip 40"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPBIW7Vhcz6aKs9REk4Rk6G","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}